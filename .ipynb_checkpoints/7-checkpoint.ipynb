{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5399e02-b914-467a-bf03-73e54ff91f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тестирование функций активации:\n",
      "==================================================\n",
      "\n",
      "Активация: sigmoid\n",
      "Выход формы: (5, 1)\n",
      "Диапазон значений: [0.1143, 0.1168]\n",
      "\n",
      "Активация: tanh\n",
      "Выход формы: (5, 1)\n",
      "Диапазон значений: [-0.0035, 0.0372]\n",
      "\n",
      "Активация: relu\n",
      "Выход формы: (5, 1)\n",
      "Диапазон значений: [0.0016, 0.0169]\n",
      "\n",
      "==================================================\n",
      "Тестирование MLP:\n",
      "Выход MLP формы: (5, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Sigmoid:\n",
    "    def __call__(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def gradient(self, x):\n",
    "        s = self.__call__(x)\n",
    "        return s * (1 - s)\n",
    "\n",
    "class Tanh:\n",
    "    def __call__(self, x):\n",
    "        return np.tanh(x)\n",
    "    \n",
    "    def gradient(self, x):\n",
    "        return 1 - np.tanh(x) ** 2\n",
    "\n",
    "class ReLU:\n",
    "    def __call__(self, x):\n",
    "        return np.maximum(0, x)\n",
    "    \n",
    "    def gradient(self, x):\n",
    "        return np.where(x > 0, 1, 0)\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, layers, activation='relu', learning_rate=0.01):\n",
    "        self.layers = []\n",
    "        self.activation_name = activation\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        for i in range(len(layers) - 1):\n",
    "            self.layers.append({\n",
    "                'weights': np.random.randn(layers[i], layers[i+1]) * 0.1,\n",
    "                'biases': np.zeros((1, layers[i+1]))\n",
    "            })\n",
    "        \n",
    "        self.set_activation(activation)\n",
    "    \n",
    "    def set_activation(self, activation_name):\n",
    "        activations = {\n",
    "            'sigmoid': Sigmoid(),\n",
    "            'tanh': Tanh(),\n",
    "            'relu': ReLU()\n",
    "        }\n",
    "        self.activation = activations.get(activation_name, ReLU())\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.a = [X]\n",
    "        self.z = []\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            z = np.dot(self.a[-1], layer['weights']) + layer['biases']\n",
    "            self.z.append(z)\n",
    "            \n",
    "            if i == len(self.layers) - 1:\n",
    "                a = z\n",
    "            else:\n",
    "                a = self.activation(z)\n",
    "            self.a.append(a)\n",
    "        \n",
    "        return self.a[-1]\n",
    "    \n",
    "    def backward(self, X, y):\n",
    "        m = X.shape[0]\n",
    "        y = y.reshape(-1, 1) if len(y.shape) == 1 else y\n",
    "        \n",
    "        self.forward(X)\n",
    "        \n",
    "        delta = self.a[-1] - y\n",
    "        dW = []\n",
    "        db = []\n",
    "        \n",
    "        for i in reversed(range(len(self.layers))):\n",
    "            if i == len(self.layers) - 1:\n",
    "                dW.insert(0, np.dot(self.a[i].T, delta) / m)\n",
    "                db.insert(0, np.sum(delta, axis=0, keepdims=True) / m)\n",
    "            else:\n",
    "                delta = np.dot(delta, self.layers[i+1]['weights'].T) * self.activation.gradient(self.z[i])\n",
    "                dW.insert(0, np.dot(self.a[i].T, delta) / m)\n",
    "                db.insert(0, np.sum(delta, axis=0, keepdims=True) / m)\n",
    "        \n",
    "        return dW, db\n",
    "    \n",
    "    def train(self, X, y, epochs=1000):\n",
    "        for epoch in range(epochs):\n",
    "            dW, db = self.backward(X, y)\n",
    "            \n",
    "            for i in range(len(self.layers)):\n",
    "                self.layers[i]['weights'] -= self.learning_rate * dW[i]\n",
    "                self.layers[i]['biases'] -= self.learning_rate * db[i]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.forward(X)\n",
    "\n",
    "class MLP:\n",
    "    def __init__(self, layers, activations=None):\n",
    "        self.layers = layers\n",
    "        if activations is None:\n",
    "            activations = ['relu'] * (len(layers) - 2) + ['linear']\n",
    "        self.activations = [self._get_activation(act) for act in activations]\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        \n",
    "        for i in range(len(layers) - 1):\n",
    "            self.weights.append(np.random.randn(layers[i], layers[i+1]) * 0.1)\n",
    "            self.biases.append(np.zeros((1, layers[i+1])))\n",
    "    \n",
    "    def _get_activation(self, name):\n",
    "        activations = {\n",
    "            'sigmoid': Sigmoid(),\n",
    "            'tanh': Tanh(),\n",
    "            'relu': ReLU(),\n",
    "            'linear': lambda x: x\n",
    "        }\n",
    "        return activations.get(name, ReLU())\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.layer_outputs = [X]\n",
    "        \n",
    "        for i in range(len(self.weights)):\n",
    "            z = np.dot(self.layer_outputs[-1], self.weights[i]) + self.biases[i]\n",
    "            a = self.activations[i](z)\n",
    "            self.layer_outputs.append(a)\n",
    "        \n",
    "        return self.layer_outputs[-1]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.forward(X)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    X = np.random.randn(100, 10)\n",
    "    y = np.random.randn(100, 1)\n",
    "    \n",
    "    print(\"Тестирование функций активации:\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    activations_to_test = ['sigmoid', 'tanh', 'relu']\n",
    "    \n",
    "    for act_name in activations_to_test:\n",
    "        print(f\"\\nАктивация: {act_name}\")\n",
    "        nn = NeuralNetwork(layers=[10, 16, 8, 1], activation=act_name, learning_rate=0.01)\n",
    "        output = nn.forward(X[:5])\n",
    "        print(f\"Выход формы: {output.shape}\")\n",
    "        print(f\"Диапазон значений: [{output.min():.4f}, {output.max():.4f}]\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Тестирование MLP:\")\n",
    "    \n",
    "    mlp = MLP(layers=[10, 20, 10, 1], \n",
    "              activations=['tanh', 'relu', 'linear'])\n",
    "    mlp_output = mlp.forward(X[:5])\n",
    "    print(f\"Выход MLP формы: {mlp_output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "878ccc32-80e0-4627-84e9-dc77f732fd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "КЛАССИФИКАЦИЯ: Набор данных Ирисы\n",
      "============================================================\n",
      "Метрики классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Setosa       1.00      1.00      1.00        19\n",
      "  Versicolor       1.00      1.00      1.00        13\n",
      "   Virginica       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      "\n",
      "Матрица ошибок:\n",
      "[[19  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0 13]]\n",
      "\n",
      "Атрибуты модели MLPClassifier:\n",
      "Количество слоев: 4\n",
      "Количество выходов: 3\n",
      "Количество итераций: 563\n",
      "Функция потерь: 0.0109\n",
      "Функция активации: relu\n",
      "Архитектура сети: (100, 50)\n",
      "\n",
      "============================================================\n",
      "РЕГРЕССИЯ: Зарплата от опыта работы\n",
      "============================================================\n",
      "R² score: 0.8941\n",
      "MSE: 54082477.79\n",
      "RMSE: 7354.08\n",
      "\n",
      "Атрибуты модели MLPRegressor:\n",
      "Количество слоев: 4\n",
      "Количество итераций: 2939\n",
      "Функция потерь: 12025960.7732\n",
      "Функция активации: relu\n",
      "Архитектура сети: (50, 25)\n",
      "Коэффициенты слоев (weights): 3 матриц\n",
      "Смещения (biases): 3 векторов\n",
      "\n",
      "============================================================\n",
      "СРАВНИТЕЛЬНЫЙ АНАЛИЗ:\n",
      "============================================================\n",
      "1. MLPClassifier:\n",
      "   - Использует cross-entropy loss для классификации\n",
      "   - На выходе вероятности через softmax\n",
      "   - Хорошо справляется с нелинейными границами решений\n",
      "   - Точность: 1.0000\n",
      "\n",
      "2. MLPRegressor:\n",
      "   - Использует MSE loss для регрессии\n",
      "   - На выходе прямое числовое значение\n",
      "   - Может моделировать сложные нелинейные зависимости\n",
      "   - Качество предсказания R²: 0.8941\n",
      "\n",
      "3. Общие атрибуты:\n",
      "   - n_layers_: общее количество слоев\n",
      "   - coefs_: веса для каждого слоя\n",
      "   - intercepts_: смещения для каждого слоя\n",
      "   - n_iter_: число итераций обучения\n",
      "   - loss_: конечное значение функции потерь\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, r2_score, mean_squared_error\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"КЛАССИФИКАЦИЯ: Набор данных Ирисы\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df_iris = pd.read_csv('iris.csv')\n",
    "X_iris = df_iris.drop('variety', axis=1)\n",
    "y_iris = df_iris['variety']\n",
    "\n",
    "X_train_iris, X_test_iris, y_train_iris, y_test_iris = train_test_split(\n",
    "    X_iris, y_iris, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "scaler_iris = StandardScaler()\n",
    "X_train_iris_scaled = scaler_iris.fit_transform(X_train_iris)\n",
    "X_test_iris_scaled = scaler_iris.transform(X_test_iris)\n",
    "\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=2000, random_state=42, alpha=0.001)\n",
    "mlp_clf.fit(X_train_iris_scaled, y_train_iris)\n",
    "\n",
    "y_pred_iris = mlp_clf.predict(X_test_iris_scaled)\n",
    "\n",
    "print(\"Метрики классификации:\")\n",
    "print(classification_report(y_test_iris, y_pred_iris))\n",
    "print(\"\\nМатрица ошибок:\")\n",
    "print(confusion_matrix(y_test_iris, y_pred_iris))\n",
    "\n",
    "print(\"\\nАтрибуты модели MLPClassifier:\")\n",
    "print(f\"Количество слоев: {mlp_clf.n_layers_}\")\n",
    "print(f\"Количество выходов: {mlp_clf.n_outputs_}\")\n",
    "print(f\"Количество итераций: {mlp_clf.n_iter_}\")\n",
    "print(f\"Функция потерь: {mlp_clf.loss_:.4f}\")\n",
    "print(f\"Функция активации: {mlp_clf.activation}\")\n",
    "print(f\"Архитектура сети: {mlp_clf.hidden_layer_sizes}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"РЕГРЕССИЯ: Зарплата от опыта работы\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df_salary = pd.read_csv('Salary_Data.csv')\n",
    "X_salary = df_salary[['YearsExperience']]\n",
    "y_salary = df_salary['Salary']\n",
    "\n",
    "X_train_salary, X_test_salary, y_train_salary, y_test_salary = train_test_split(\n",
    "    X_salary, y_salary, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "scaler_salary = StandardScaler()\n",
    "X_train_salary_scaled = scaler_salary.fit_transform(X_train_salary)\n",
    "X_test_salary_scaled = scaler_salary.transform(X_test_salary)\n",
    "\n",
    "mlp_reg = MLPRegressor(hidden_layer_sizes=(50, 25), max_iter=5000, random_state=42, alpha=0.001, learning_rate_init=0.01)\n",
    "mlp_reg.fit(X_train_salary_scaled, y_train_salary)\n",
    "\n",
    "y_pred_salary = mlp_reg.predict(X_test_salary_scaled)\n",
    "\n",
    "r2 = r2_score(y_test_salary, y_pred_salary)\n",
    "mse = mean_squared_error(y_test_salary, y_pred_salary)\n",
    "\n",
    "print(f\"R² score: {r2:.4f}\")\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "print(f\"RMSE: {np.sqrt(mse):.2f}\")\n",
    "\n",
    "print(\"\\nАтрибуты модели MLPRegressor:\")\n",
    "print(f\"Количество слоев: {mlp_reg.n_layers_}\")\n",
    "print(f\"Количество итераций: {mlp_reg.n_iter_}\")\n",
    "print(f\"Функция потерь: {mlp_reg.loss_:.4f}\")\n",
    "print(f\"Функция активации: {mlp_reg.activation}\")\n",
    "print(f\"Архитектура сети: {mlp_reg.hidden_layer_sizes}\")\n",
    "print(f\"Коэффициенты слоев (weights): {len(mlp_reg.coefs_)} матриц\")\n",
    "print(f\"Смещения (biases): {len(mlp_reg.intercepts_)} векторов\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"СРАВНИТЕЛЬНЫЙ АНАЛИЗ:\")\n",
    "print(\"=\"*60)\n",
    "print(\"1. MLPClassifier:\")\n",
    "print(\"   - Использует cross-entropy loss для классификации\")\n",
    "print(\"   - На выходе вероятности через softmax\")\n",
    "print(\"   - Хорошо справляется с нелинейными границами решений\")\n",
    "print(f\"   - Точность: {mlp_clf.score(X_test_iris_scaled, y_test_iris):.4f}\")\n",
    "\n",
    "print(\"\\n2. MLPRegressor:\")\n",
    "print(\"   - Использует MSE loss для регрессии\")\n",
    "print(\"   - На выходе прямое числовое значение\")\n",
    "print(\"   - Может моделировать сложные нелинейные зависимости\")\n",
    "print(f\"   - Качество предсказания R²: {r2:.4f}\")\n",
    "\n",
    "print(\"\\n3. Общие атрибуты:\")\n",
    "print(\"   - n_layers_: общее количество слоев\")\n",
    "print(\"   - coefs_: веса для каждого слоя\")\n",
    "print(\"   - intercepts_: смещения для каждого слоя\")\n",
    "print(\"   - n_iter_: число итераций обучения\")\n",
    "print(\"   - loss_: конечное значение функции потерь\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff5edf59-450a-4917-b0fc-4f5f82cd018a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\artem\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\artem\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\ops\\nn.py:946: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4960 - loss: 0.7048   \n",
      "Epoch 2/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4960 - loss: 0.6969 \n",
      "Epoch 3/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4960 - loss: 0.6967 \n",
      "Epoch 4/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4960 - loss: 0.6925 \n",
      "Epoch 5/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4960 - loss: 0.6922 \n",
      "Epoch 6/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4960 - loss: 0.6906 \n",
      "Epoch 7/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4960 - loss: 0.6943 \n",
      "Epoch 8/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4960 - loss: 0.6903 \n",
      "Epoch 9/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4960 - loss: 0.6938\n",
      "Epoch 10/10\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4960 - loss: 0.6920\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4960 - loss: 0.6989  \n",
      "Loss: 0.6989213824272156, Accuracy: 0.4959999918937683\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "X = np.random.rand(1000, 20)\n",
    "y = np.random.randint(2, size=(1000, 1))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=20, activation='tanh'))\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, y, epochs=10, batch_size=32)\n",
    "\n",
    "loss, accuracy = model.evaluate(X, y)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be88ab06-6441-4795-b69d-a1e7da95ea6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype(\"float32\") / 255\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(train_images, train_labels, \n",
    "                    epochs=20, \n",
    "                    batch_size=64)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f\"\\nТочность на контрольном наборе: {test_acc:.4f}\")\n",
    "\n",
    "test_digits = test_images[0:10]\n",
    "predictions = model.predict(test_digits)\n",
    "\n",
    "print(\"\\nПроверка предсказаний для первых 10 изображений:\")\n",
    "for i in range(10):\n",
    "    predicted_label = predictions[i].argmax()\n",
    "    true_label = test_labels[i]\n",
    "    correct = \"✓\" if predicted_label == true_label else \"✗\"\n",
    "    print(f\"Изображение {i}: предсказано {predicted_label}, реально {true_label} {correct}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e544b06a-6fc9-4e47-83d9-9edf9e0ec90c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layers\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mnist\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype(\"float32\") / 255\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ПРИМЕР 3: Оригинальная CNN модель (3 Conv2D, 2 MaxPooling2D)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "inputs_original = keras.Input(shape=(28, 28, 1))\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs_original)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "outputs_original = layers.Dense(10, activation=\"softmax\")(x)\n",
    "model_original = keras.Model(inputs=inputs_original, outputs=outputs_original)\n",
    "\n",
    "model_original.compile(optimizer=\"rmsprop\",\n",
    "                      loss=\"sparse_categorical_crossentropy\",\n",
    "                      metrics=[\"accuracy\"])\n",
    "\n",
    "history_original = model_original.fit(train_images, train_labels, \n",
    "                                     epochs=5, \n",
    "                                     batch_size=64,\n",
    "                                     validation_split=0.1,\n",
    "                                     verbose=1)\n",
    "\n",
    "test_loss_original, test_acc_original = model_original.evaluate(test_images, test_labels, verbose=0)\n",
    "print(f\"\\nТочность оригинальной модели на тестовых данных: {test_acc_original:.4f}\")\n",
    "\n",
    "# 2. Новая модель с 5 слоями Conv2D и 4 слоями MaxPooling2D\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"НОВАЯ МОДЕЛЬ: 5 Conv2D, 4 MaxPooling2D\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "inputs_new = keras.Input(shape=(28, 28, 1))\n",
    "\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\", padding='same')(inputs_new)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\", padding='same')(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\", padding='same')(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\", padding='same')(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\", padding='same')(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\", padding='valid')(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "\n",
    "x = layers.Conv2D(filters=512, kernel_size=2, activation=\"relu\", padding='valid')(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs_new = layers.Dense(10, activation=\"softmax\")(x)\n",
    "model_new = keras.Model(inputs=inputs_new, outputs=outputs_new)\n",
    "\n",
    "model_new.compile(optimizer=\"rmsprop\",\n",
    "                 loss=\"sparse_categorical_crossentropy\",\n",
    "                 metrics=[\"accuracy\"])\n",
    "\n",
    "history_new = model_new.fit(train_images, train_labels, \n",
    "                           epochs=5, \n",
    "                           batch_size=64,\n",
    "                           validation_split=0.1,\n",
    "                           verbose=1)\n",
    "\n",
    "test_loss_new, test_acc_new = model_new.evaluate(test_images, test_labels, verbose=0)\n",
    "print(f\"\\nТочность новой модели на тестовых данных: {test_acc_new:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"СРАВНЕНИЕ РЕЗУЛЬТАТОВ\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Оригинальная модель (3 Conv2D, 2 MaxPooling2D):\")\n",
    "print(f\"  - Точность: {test_acc_original:.4f}\")\n",
    "print(f\"  - Параметры: {model_original.count_params():,}\")\n",
    "print(f\"  - Архитектура: Conv2D(32) → MaxPool → Conv2D(64) → MaxPool → Conv2D(128)\")\n",
    "\n",
    "print(f\"\\nНовая модель (5 Conv2D, 4 MaxPooling2D):\")\n",
    "print(f\"  - Точность: {test_acc_new:.4f}\")\n",
    "print(f\"  - Параметры: {model_new.count_params():,}\")\n",
    "print(f\"  - Архитектура: Conv2D(32)x2 → MaxPool → Conv2D(64)x2 → MaxPool → Conv2D(128) → MaxPool → Conv2D(256) → MaxPool → Conv2D(512)\")\n",
    "\n",
    "print(f\"\\nРазница в точности: {test_acc_new - test_acc_original:+.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"СРАВНЕНИЕ ПРОЦЕССА ОБУЧЕНИЯ\")\n",
    "print(\"=\"*60)\n",
    "print(\"Оригинальная модель - последняя эпоха:\")\n",
    "print(f\"  - Loss: {history_original.history['loss'][-1]:.4f}\")\n",
    "print(f\"  - Accuracy: {history_original.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"  - Val Accuracy: {history_original.history['val_accuracy'][-1]:.4f}\")\n",
    "\n",
    "print(\"\\nНовая модель - последняя эпоха:\")\n",
    "print(f\"  - Loss: {history_new.history['loss'][-1]:.4f}\")\n",
    "print(f\"  - Accuracy: {history_new.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"  - Val Accuracy: {history_new.history['val_accuracy'][-1]:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ПРОВЕРКА ПРЕДСКАЗАНИЙ\")\n",
    "print(\"=\"*60)\n",
    "sample_images = test_images[:5]\n",
    "predictions_original = model_original.predict(sample_images)\n",
    "predictions_new = model_new.predict(sample_images)\n",
    "\n",
    "for i in range(5):\n",
    "    pred_original = np.argmax(predictions_original[i])\n",
    "    pred_new = np.argmax(predictions_new[i])\n",
    "    true_label = test_labels[i]\n",
    "    \n",
    "    original_correct = \"✓\" if pred_original == true_label else \"✗\"\n",
    "    new_correct = \"✓\" if pred_new == true_label else \"✗\"\n",
    "    \n",
    "    print(f\"Изображение {i}: Истинное = {true_label}\")\n",
    "    print(f\"  Оригинальная модель: {pred_original} {original_correct}\")\n",
    "    print(f\"  Новая модель: {pred_new} {new_correct}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9092ad7-a908-413d-9c24-19e4690819fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cifar10\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dense, Flatten, Activation, Dropout\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Activation, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"1. ПРОСМОТР ДАННЫХ CIFAR-10\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(X_train[i])\n",
    "    plt.title(class_names[y_train[i][0]], fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"2. ПОДГОТОВКА ДАННЫХ И ПАРАМЕТРЫ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "batch_size = 32\n",
    "nb_classes = 10\n",
    "nb_epoch = 30\n",
    "img_rows, img_cols = 32, 32\n",
    "img_channels = 3\n",
    "\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "Y_train = to_categorical(y_train, nb_classes)\n",
    "Y_test = to_categorical(y_test, nb_classes)\n",
    "\n",
    "print(f\"Размер тренировочных данных: {X_train.shape}\")\n",
    "print(f\"Размер тестовых данных: {X_test.shape}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"3. СОЗДАНИЕ УЛУЧШЕННОЙ МОДЕЛИ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def create_improved_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), padding='same', input_shape=(32, 32, 3), activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_improved_model()\n",
    "\n",
    "sgd = SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(\"Архитектура улучшенной модели:\")\n",
    "model.summary()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"4. ОБУЧЕНИЕ С ВАЛИДАЦИЕЙ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_val, X_val, Y_train_val, Y_val = train_test_split(\n",
    "    X_train, Y_train, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "history = model.fit(X_train_val, Y_train_val,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=nb_epoch,\n",
    "                    validation_data=(X_val, Y_val),\n",
    "                    shuffle=True,\n",
    "                    verbose=1,\n",
    "                    callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"5. ОЦЕНКА МОДЕЛИ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(f\"Точность работы на тестовых данных: {scores[1]*100:.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"6. ВИЗУАЛИЗАЦИЯ РЕЗУЛЬТАТОВ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"7. ОБУЧЕНИЕ НА ПОЛНОМ ОБЪЕМЕ ДАННЫХ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "final_model = create_improved_model()\n",
    "final_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history_final = final_model.fit(X_train, Y_train,\n",
    "                                batch_size=64,  \n",
    "                                epochs=25,     \n",
    "                                shuffle=True,\n",
    "                                verbose=1,\n",
    "                                validation_split=0.1,  \n",
    "                                callbacks=[early_stopping])\n",
    "\n",
    "final_scores = final_model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(f\"Финальная точность на тестовых данных: {final_scores[1]*100:.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"8. СРАВНЕНИЕ С ИСХОДНОЙ МОДЕЛЬЮ\")\n",
    "print(\"=\"*60)\n",
    "print(\"Исходная модель из примера 4: ~73.99% точности\")\n",
    "print(f\"Улучшенная модель с валидацией: {scores[1]*100:.2f}% точности\")\n",
    "print(f\"Финальная модель (полный датасет): {final_scores[1]*100:.2f}% точности\")\n",
    "print(f\"Улучшение: +{final_scores[1]*100 - 73.99:.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"9. ПРОВЕРКА ПРЕДСКАЗАНИЙ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "sample_indices = np.random.choice(len(X_test), 10, replace=False)\n",
    "sample_images = X_test[sample_indices]\n",
    "sample_labels = y_test[sample_indices]\n",
    "\n",
    "predictions = final_model.predict(sample_images)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(sample_images[i])\n",
    "    \n",
    "    true_label = class_names[sample_labels[i][0]]\n",
    "    pred_label = class_names[predicted_classes[i]]\n",
    "    \n",
    "    color = 'green' if true_label == pred_label else 'red'\n",
    "    plt.title(f\"True: {true_label}\\nPred: {pred_label}\", color=color, fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nСтатистика улучшений:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"1. Увеличение количества карт признаков: 32→64→128→256→512\")\n",
    "print(\"2. Добавление большего количества сверточных слоев (4 блока)\")\n",
    "print(\"3. Использование Dropout после каждого бока для регуляризации\")\n",
    "print(\"4. Добавление полносвязных слоев (1024 и 512 нейронов)\")\n",
    "print(\"5. Использование Adam вместо SGD оптимизатора\")\n",
    "print(\"6. Применение EarlyStopping и ReduceLROnPlateau\")\n",
    "print(\"7. Увеличение размера batch_size при финальном обучении\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22e9065-8497-4e1b-818e-7e0708b1974d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
